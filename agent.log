2024-12-17 18:15:45,403 INFO - Starting the application...
2024-12-17 18:15:46,259 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.22:8000
2024-12-17 18:15:46,259 INFO - [33mPress CTRL+C to quit[0m
2024-12-17 18:15:46,261 INFO -  * Restarting with stat
2024-12-17 18:15:48,506 INFO - Starting the application...
2024-12-17 18:15:48,516 WARNING -  * Debugger is active!
2024-12-17 18:15:48,526 INFO -  * Debugger PIN: 798-604-046
2024-12-17 18:16:34,790 DEBUG - Received query: hello
2024-12-17 18:16:34,800 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-17 18:16:34,829 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-17 18:16:34,829 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-17 18:16:34,904 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F7F6E3AE60>
2024-12-17 18:16:34,904 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F7F6D104C0> server_hostname='api.openai.com' timeout=5.0
2024-12-17 18:16:35,173 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F7F6E3AEF0>
2024-12-17 18:16:35,174 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-17 18:16:35,174 DEBUG - send_request_headers.complete
2024-12-17 18:16:35,174 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-17 18:16:35,174 DEBUG - send_request_body.complete
2024-12-17 18:16:35,174 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-17 18:16:35,670 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 18 Dec 2024 02:16:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199942'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_bc307d287c1a640d8ca8596880d91fc5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=CpIS1_.ZBywoHYpu2FFz7_gAMWt8LNzV7b8kAiLnv5Q-1734488195-1.0.1.1-0iWnSogXGI4VNoLsn3MoQjWV5DGEEPQmTw6M0ooXW7EYfZ_.3eokPCrhKWvG3MvWKmLQ1uyCIiQ1C8pmpmGlHw; path=/; expires=Wed, 18-Dec-24 02:46:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Fb51uo4UlncyiLpbDaL9E9o2eD4A6eyKlF9JUi8a.Tk-1734488195453-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f3ba6d2af67ed3c-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-17 18:16:35,671 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-17 18:16:35,671 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-17 18:16:35,671 DEBUG - receive_response_body.complete
2024-12-17 18:16:35,671 DEBUG - response_closed.started
2024-12-17 18:16:35,671 DEBUG - response_closed.complete
2024-12-17 18:16:35,671 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Wed, 18 Dec 2024 02:16:35 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9rrum9u9hev9vwb50ku6dbbv'), ('openai-processing-ms', '430'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199942'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '17ms'), ('x-request-id', 'req_bc307d287c1a640d8ca8596880d91fc5'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=CpIS1_.ZBywoHYpu2FFz7_gAMWt8LNzV7b8kAiLnv5Q-1734488195-1.0.1.1-0iWnSogXGI4VNoLsn3MoQjWV5DGEEPQmTw6M0ooXW7EYfZ_.3eokPCrhKWvG3MvWKmLQ1uyCIiQ1C8pmpmGlHw; path=/; expires=Wed, 18-Dec-24 02:46:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Fb51uo4UlncyiLpbDaL9E9o2eD4A6eyKlF9JUi8a.Tk-1734488195453-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f3ba6d2af67ed3c-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-17 18:16:35,672 DEBUG - request_id: req_bc307d287c1a640d8ca8596880d91fc5
2024-12-17 18:16:35,677 INFO - Assistant response: Hello! How can I assist you today?
2024-12-17 18:16:35,678 INFO - 127.0.0.1 - - [17/Dec/2024 18:16:35] "POST /query HTTP/1.1" 200 -
2024-12-17 18:16:37,645 DEBUG - Received query: Im just chillin how about you
2024-12-17 18:16:37,655 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-17 18:16:37,657 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-17 18:16:37,657 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-17 18:16:37,658 DEBUG - send_request_headers.complete
2024-12-17 18:16:37,658 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-17 18:16:37,658 DEBUG - send_request_body.complete
2024-12-17 18:16:37,658 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-17 18:16:38,278 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 18 Dec 2024 02:16:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199915'), (b'x-ratelimit-reset-requests', b'14.802s'), (b'x-ratelimit-reset-tokens', b'25ms'), (b'x-request-id', b'req_4f61ea92313d7ba9c402bd54f15efd9d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f3ba6e22d16ed3c-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-17 18:16:38,279 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-17 18:16:38,279 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-17 18:16:38,282 DEBUG - receive_response_body.complete
2024-12-17 18:16:38,282 DEBUG - response_closed.started
2024-12-17 18:16:38,282 DEBUG - response_closed.complete
2024-12-17 18:16:38,282 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 18 Dec 2024 02:16:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '538', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199915', 'x-ratelimit-reset-requests': '14.802s', 'x-ratelimit-reset-tokens': '25ms', 'x-request-id': 'req_4f61ea92313d7ba9c402bd54f15efd9d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f3ba6e22d16ed3c-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-17 18:16:38,282 DEBUG - request_id: req_4f61ea92313d7ba9c402bd54f15efd9d
2024-12-17 18:16:38,283 INFO - Assistant response: I'm here to help you with any Kubernetes queries you might have!
2024-12-17 18:16:38,283 INFO - 127.0.0.1 - - [17/Dec/2024 18:16:38] "POST /query HTTP/1.1" 200 -
2024-12-17 18:16:42,877 DEBUG - Received query: Tell  me about my kubernetes server
2024-12-17 18:16:42,892 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}, {'role': 'assistant', 'content': "I'm here to help you with any Kubernetes queries you might have!"}, {'role': 'assistant', 'content': "I'm here to help you with any Kubernetes queries you might have!"}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-17 18:16:42,893 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-17 18:16:42,894 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-17 18:16:42,894 DEBUG - send_request_headers.complete
2024-12-17 18:16:42,894 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-17 18:16:42,894 DEBUG - send_request_body.complete
2024-12-17 18:16:42,895 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-17 18:16:43,784 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 18 Dec 2024 02:16:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'830'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199871'), (b'x-ratelimit-reset-requests', b'18.207s'), (b'x-ratelimit-reset-tokens', b'38ms'), (b'x-request-id', b'req_c108bd4cd2b5c68311ed8f1acc067386'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f3ba702eea9ed3c-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-17 18:16:43,785 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-17 18:16:43,785 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-17 18:16:43,789 DEBUG - receive_response_body.complete
2024-12-17 18:16:43,790 DEBUG - response_closed.started
2024-12-17 18:16:43,790 DEBUG - response_closed.complete
2024-12-17 18:16:43,790 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 18 Dec 2024 02:16:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '830', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199871', 'x-ratelimit-reset-requests': '18.207s', 'x-ratelimit-reset-tokens': '38ms', 'x-request-id': 'req_c108bd4cd2b5c68311ed8f1acc067386', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f3ba702eea9ed3c-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-17 18:16:43,790 DEBUG - request_id: req_c108bd4cd2b5c68311ed8f1acc067386
2024-12-17 18:16:43,794 DEBUG - Starting new HTTP connection (1): 127.0.0.1:8000
2024-12-17 18:16:43,819 DEBUG - response body: {"kind":"NodeList","apiVersion":"v1","metadata":{"resourceVersion":"35473"},"items":[{"metadata":{"name":"minikube","uid":"1da6d62b-9b18-47da-9512-6a5783379000","resourceVersion":"35393","creationTimestamp":"2024-12-03T16:52:25Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube","kubernetes.io/os":"linux","minikube.k8s.io/commit":"210b148df93a80eb872ecbeb7e35281b3c582c61","minikube.k8s.io/name":"minikube","minikube.k8s.io/primary":"true","minikube.k8s.io/updated_at":"2024_12_03T08_52_29_0700","minikube.k8s.io/version":"v1.34.0","node-role.kubernetes.io/control-plane":"","node.kubernetes.io/exclude-from-external-load-balancers":""},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"unix:///var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}}},{"manager":"kubectl-label","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:30Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}}},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.0.0/24\"":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-12-18T02:15:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:nodeInfo":{"f:bootID":{},"f:machineID":{},"f:systemUUID":{}}}},"subresource":"status"}]},"spec":{"podCIDR":"10.244.0.0/24","podCIDRs":["10.244.0.0/24"]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"1055762868Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"16344240Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"1055762868Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"16344240Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2024-12-18T02:15:03Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2024-12-18T02:15:03Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2024-12-18T02:15:03Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"True","lastHeartbeatTime":"2024-12-18T02:15:03Z","lastTransitionTime":"2024-12-03T16:52:25Z","reason":"KubeletReady","message":"kubelet is posting ready status"}],"addresses":[{"type":"InternalIP","address":"192.168.49.2"},{"type":"Hostname","address":"minikube"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"50ab5353abd2455487624ff1f305d84a","systemUUID":"50ab5353abd2455487624ff1f305d84a","bootID":"6de36fcc-1673-4f6d-ba93-2c477ded20e1","kernelVersion":"5.15.167.4-microsoft-standard-WSL2","osImage":"Ubuntu 22.04.4 LTS","containerRuntimeVersion":"docker://27.2.0","kubeletVersion":"v1.31.0","kubeProxyVersion":"","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["registry.k8s.io/etcd@sha256:a6dc63e6e8cfa0307d7851762fa6b629afb18f28d8aa3fab5a6e91b4af60026a","registry.k8s.io/etcd:3.5.15-0"],"sizeBytes":147945345},{"names":["registry.k8s.io/kube-apiserver@sha256:470179274deb9dc3a81df55cfc24823ce153147d4ebf2ed649a4f271f51eaddf","registry.k8s.io/kube-apiserver:v1.31.0"],"sizeBytes":94175876},{"names":["registry.k8s.io/kube-proxy@sha256:c727efb1c6f15a68060bf7f207f5c7a765355b7e3340c513e582ec819c5cd2fe","registry.k8s.io/kube-proxy:v1.31.0"],"sizeBytes":91471299},{"names":["registry.k8s.io/kube-controller-manager@sha256:f6f3c33dda209e8434b83dacf5244c03b59b0018d93325ff21296a142b68497d","registry.k8s.io/kube-controller-manager:v1.31.0"],"sizeBytes":88380387},{"names":["registry.k8s.io/kube-scheduler@sha256:96ddae9c9b2e79342e0551e2d2ec422c0c02629a74d928924aaa069706619808","registry.k8s.io/kube-scheduler:v1.31.0"],"sizeBytes":67363811},{"names":["registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1","registry.k8s.io/coredns/coredns:v1.11.1"],"sizeBytes":59820619},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a","registry.k8s.io/pause:3.10"],"sizeBytes":735760}]}}]}

2024-12-17 18:16:43,846 DEBUG - response body: {"kind":"ServiceList","apiVersion":"v1","metadata":{"resourceVersion":"35473"},"items":[{"metadata":{"name":"kubernetes","namespace":"default","uid":"a05e95ef-8a1b-4fa0-947f-93ae32dae6e5","resourceVersion":"199","creationTimestamp":"2024-12-03T16:52:27Z","labels":{"component":"apiserver","provider":"kubernetes"},"managedFields":[{"manager":"kube-apiserver","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{".":{},"f:component":{},"f:provider":{}}},"f:spec":{"f:clusterIP":{},"f:internalTrafficPolicy":{},"f:ipFamilyPolicy":{},"f:ports":{".":{},"k:{\"port\":443,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}}}]},"spec":{"ports":[{"name":"https","protocol":"TCP","port":443,"targetPort":8443}],"clusterIP":"10.96.0.1","clusterIPs":["10.96.0.1"],"type":"ClusterIP","sessionAffinity":"None","ipFamilies":["IPv4"],"ipFamilyPolicy":"SingleStack","internalTrafficPolicy":"Cluster"},"status":{"loadBalancer":{}}}]}

2024-12-17 18:16:43,866 DEBUG - response body: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35473"},"items":[]}

2024-12-17 18:16:43,886 DEBUG - response body: {"kind":"DeploymentList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35473"},"items":[]}

2024-12-17 18:16:43,887 INFO - 127.0.0.1 - - [17/Dec/2024 18:16:43] "GET /get_kube_api HTTP/1.1" 200 -
2024-12-17 18:16:43,908 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}, {'role': 'assistant', 'content': "I'm here to help you with any Kubernetes queries you might have!"}, {'role': 'assistant', 'content': "I'm here to help you with any Kubernetes queries you might have!"}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_1MgWg5KhtcKckEWJztFLvpe0', 'function': {'arguments': '{"query":"Tell me about my Kubernetes server","answer":"Fetching information about your Kubernetes server."}', 'name': 'get_cluster_information'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_1MgWg5KhtcKckEWJztFLvpe0', 'name': 'get_cluster_information', 'content': '{"query":"Tell  me about my kubernetes server","answer":"{\\"answer\\": \\"\\\\\\"{\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"minikube\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"status\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"role\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"unknown\\\\\\\\\\\\\\"}], \\\\\\\\\\\\\\"pods\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"deployments\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"services\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"kubernetes\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"type\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"ClusterIP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"cluster_ip\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"10.96.0.1\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"ports\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"https\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"protocol\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"TCP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"port\\\\\\\\\\\\\\": 443, \\\\\\\\\\\\\\"target_port\\\\\\\\\\\\\\": 8443, \\\\\\\\\\\\\\"node_port\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\"app_protocol\\\\\\\\\\\\\\": null}]}]}\\\\\\"\\", \\"query\\": \\"Get Kubernetes Cluster Info\\"}"}'}], 'model': 'gpt-4o-mini', 'tool_choice': None, 'tools': None}}
2024-12-17 18:16:43,909 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-17 18:16:43,910 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-17 18:16:43,910 DEBUG - send_request_headers.complete
2024-12-17 18:16:43,910 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-17 18:16:43,910 DEBUG - send_request_body.complete
2024-12-17 18:16:43,910 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-17 18:16:45,581 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 18 Dec 2024 02:16:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'1606'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199671'), (b'x-ratelimit-reset-requests', b'25.836s'), (b'x-ratelimit-reset-tokens', b'98ms'), (b'x-request-id', b'req_a0abcd11898432eb67f204e73b19b1f5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f3ba7094e39ed3c-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-17 18:16:45,582 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-17 18:16:45,582 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-17 18:16:45,582 DEBUG - receive_response_body.complete
2024-12-17 18:16:45,583 DEBUG - response_closed.started
2024-12-17 18:16:45,583 DEBUG - response_closed.complete
2024-12-17 18:16:45,583 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 18 Dec 2024 02:16:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '1606', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199671', 'x-ratelimit-reset-requests': '25.836s', 'x-ratelimit-reset-tokens': '98ms', 'x-request-id': 'req_a0abcd11898432eb67f204e73b19b1f5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f3ba7094e39ed3c-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-17 18:16:45,583 DEBUG - request_id: req_a0abcd11898432eb67f204e73b19b1f5
2024-12-17 18:16:45,584 INFO - Assistant response: Your Kubernetes server has the following information:

- **Nodes**: 
  - Name: minikube
  - Status: Ready
  - Role: Unknown

- **Pods**: None

- **Deployments**: None

- **Services**:
  - Name: kubernetes
  - Type: ClusterIP
  - Cluster IP: 10.96.0.1
  - Ports: 
    - Name: https
    - Protocol: TCP
    - Port: 443
    - Target Port: 8443
2024-12-17 18:16:45,584 INFO - 127.0.0.1 - - [17/Dec/2024 18:16:45] "POST /query HTTP/1.1" 200 -
