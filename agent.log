2024-12-03 23:03:47,491 INFO - Starting the application...
2024-12-03 23:03:47,502 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:03:47,502 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:04:42,791 INFO - Starting the application...
2024-12-03 23:04:42,802 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:04:42,802 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:05:28,107 INFO - Starting the application...
2024-12-03 23:05:28,118 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:05:28,118 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:08:11,877 INFO - Starting the application...
2024-12-03 23:08:11,889 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:08:11,890 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:08:53,482 INFO - Starting the application...
2024-12-03 23:08:53,499 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:08:53,499 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:08:53,501 INFO -  * Restarting with stat
2024-12-03 23:08:55,616 INFO - Starting the application...
2024-12-03 23:08:55,626 WARNING -  * Debugger is active!
2024-12-03 23:08:55,631 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:09:32,023 INFO -  * Detected change in 'C:\\Users\\Reason\\Desktop\\POST GRADUATION\\Job Search\\Cleric\\main.py', reloading
2024-12-03 23:09:32,184 INFO -  * Restarting with stat
2024-12-03 23:10:43,143 INFO - Starting the application...
2024-12-03 23:10:43,158 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-03 23:10:43,158 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:10:43,160 INFO -  * Restarting with stat
2024-12-03 23:10:45,246 INFO - Starting the application...
2024-12-03 23:10:45,255 WARNING -  * Debugger is active!
2024-12-03 23:10:45,261 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:10:55,433 DEBUG - Received query: hello
2024-12-03 23:10:55,440 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:10:55,461 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:10:55,461 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:10:55,532 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000195B33C2770>
2024-12-03 23:10:55,532 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000195B328C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:10:55,571 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000195B33C2800>
2024-12-03 23:10:55,571 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:10:55,572 DEBUG - send_request_headers.complete
2024-12-03 23:10:55,572 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:10:55,572 DEBUG - send_request_body.complete
2024-12-03 23:10:55,572 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:10:56,453 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:10:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'585'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199942'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_b64758f198bde1499d5013de52f12c26'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JMZaiwFzWEudsm3D2ewbJAjiwr03JpX60IXByn0WarQ-1733296255-1.0.1.1-IL9KYVUlILSIXRWI.nLeqjljWNhJ.G4uO0dXZWhk7EEBZM55W89WZKXYJjEq1bnsADNYVldgRWJcT4MOiQZI8A; path=/; expires=Wed, 04-Dec-24 07:40:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=62fLimySkvzGqkMWBzbn3_Uw0Eb1sq6QlR3u9xaibTU-1733296255785-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ec9fab95c4aebe3-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:10:56,454 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:10:56,454 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:10:56,454 DEBUG - receive_response_body.complete
2024-12-03 23:10:56,454 DEBUG - response_closed.started
2024-12-03 23:10:56,454 DEBUG - response_closed.complete
2024-12-03 23:10:56,455 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Wed, 04 Dec 2024 07:10:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9rrum9u9hev9vwb50ku6dbbv'), ('openai-processing-ms', '585'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199942'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '17ms'), ('x-request-id', 'req_b64758f198bde1499d5013de52f12c26'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=JMZaiwFzWEudsm3D2ewbJAjiwr03JpX60IXByn0WarQ-1733296255-1.0.1.1-IL9KYVUlILSIXRWI.nLeqjljWNhJ.G4uO0dXZWhk7EEBZM55W89WZKXYJjEq1bnsADNYVldgRWJcT4MOiQZI8A; path=/; expires=Wed, 04-Dec-24 07:40:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=62fLimySkvzGqkMWBzbn3_Uw0Eb1sq6QlR3u9xaibTU-1733296255785-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8ec9fab95c4aebe3-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-03 23:10:56,455 DEBUG - request_id: req_b64758f198bde1499d5013de52f12c26
2024-12-03 23:10:56,460 INFO - Assistant response: Hello! How can I assist you with Kubernetes today?
2024-12-03 23:10:56,461 INFO - 127.0.0.1 - - [03/Dec/2024 23:10:56] "POST /query HTTP/1.1" 200 -
2024-12-03 23:11:24,190 INFO - Starting the application...
2024-12-03 23:11:24,206 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-03 23:11:24,206 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:11:24,207 INFO -  * Restarting with stat
2024-12-03 23:11:26,325 INFO - Starting the application...
2024-12-03 23:11:26,334 WARNING -  * Debugger is active!
2024-12-03 23:11:26,340 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:13:53,021 INFO -  * Detected change in 'C:\\Users\\Reason\\Desktop\\POST GRADUATION\\Job Search\\Cleric\\main.py', reloading
2024-12-03 23:13:53,238 INFO -  * Restarting with stat
2024-12-03 23:13:55,556 INFO - Starting the application...
2024-12-03 23:13:55,566 WARNING -  * Debugger is active!
2024-12-03 23:13:55,572 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:14:08,735 INFO -  * Detected change in 'C:\\Users\\Reason\\Desktop\\POST GRADUATION\\Job Search\\Cleric\\util.py', reloading
2024-12-03 23:14:08,907 INFO -  * Restarting with stat
2024-12-03 23:14:11,321 INFO - Starting the application...
2024-12-03 23:14:11,330 WARNING -  * Debugger is active!
2024-12-03 23:14:11,336 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:14:18,451 INFO -  * Detected change in 'C:\\Users\\Reason\\Desktop\\POST GRADUATION\\Job Search\\Cleric\\util.py', reloading
2024-12-03 23:14:18,619 INFO -  * Restarting with stat
2024-12-03 23:14:20,832 INFO - Starting the application...
2024-12-03 23:14:20,841 WARNING -  * Debugger is active!
2024-12-03 23:14:20,846 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:15:07,793 INFO - Starting the application...
2024-12-03 23:15:07,811 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:15:07,811 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:15:07,812 INFO -  * Restarting with stat
2024-12-03 23:15:10,059 INFO - Starting the application...
2024-12-03 23:15:10,068 WARNING -  * Debugger is active!
2024-12-03 23:15:10,073 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:15:26,492 DEBUG - Received query: hello
2024-12-03 23:15:26,499 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:15:26,520 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:15:26,521 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:15:26,586 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D831A564D0>
2024-12-03 23:15:26,586 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D83191C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:15:26,624 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D831A56560>
2024-12-03 23:15:26,625 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:15:26,625 DEBUG - send_request_headers.complete
2024-12-03 23:15:26,625 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:15:26,625 DEBUG - send_request_body.complete
2024-12-03 23:15:26,625 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:15:26,991 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:15:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'293'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199942'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_ba676fc2303aa59bbec3f6662315aa9d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xvXMrPWlW1LMMRvGjuvrQn6Y4dBZ2dBwqGJyDUOWMw4-1733296526-1.0.1.1-dPBtfDmts9Jg4tc2R_eJOrCyDuD4J38I_qxrtgIUVuvMAeHd3eFsWfwu3LKSr8Fgv7MZ0akIOuxaKitlr64ksg; path=/; expires=Wed, 04-Dec-24 07:45:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=e38pbZMJHZL0jCW_9JavQz5YcTKvUB5li7mHACcJISI-1733296526320-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca01576e4deb2c-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:15:26,992 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:15:26,992 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:15:26,992 DEBUG - receive_response_body.complete
2024-12-03 23:15:26,993 DEBUG - response_closed.started
2024-12-03 23:15:26,993 DEBUG - response_closed.complete
2024-12-03 23:15:26,993 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Wed, 04 Dec 2024 07:15:26 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9rrum9u9hev9vwb50ku6dbbv'), ('openai-processing-ms', '293'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199942'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '17ms'), ('x-request-id', 'req_ba676fc2303aa59bbec3f6662315aa9d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=xvXMrPWlW1LMMRvGjuvrQn6Y4dBZ2dBwqGJyDUOWMw4-1733296526-1.0.1.1-dPBtfDmts9Jg4tc2R_eJOrCyDuD4J38I_qxrtgIUVuvMAeHd3eFsWfwu3LKSr8Fgv7MZ0akIOuxaKitlr64ksg; path=/; expires=Wed, 04-Dec-24 07:45:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=e38pbZMJHZL0jCW_9JavQz5YcTKvUB5li7mHACcJISI-1733296526320-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8eca01576e4deb2c-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-03 23:15:26,993 DEBUG - request_id: req_ba676fc2303aa59bbec3f6662315aa9d
2024-12-03 23:15:26,999 INFO - Assistant response: Hello! How can I assist you today?
2024-12-03 23:15:27,000 INFO - 127.0.0.1 - - [03/Dec/2024 23:15:27] "POST /query HTTP/1.1" 200 -
2024-12-03 23:16:04,791 INFO - Starting the application...
2024-12-03 23:16:04,808 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:16:04,808 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:16:04,810 INFO -  * Restarting with stat
2024-12-03 23:16:07,123 INFO - Starting the application...
2024-12-03 23:16:07,133 WARNING -  * Debugger is active!
2024-12-03 23:16:07,139 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:29:59,934 DEBUG - Received query: hello
2024-12-03 23:29:59,942 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:29:59,968 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:29:59,969 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:30:00,060 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000273B2AC6560>
2024-12-03 23:30:00,061 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000273B298C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:30:00,103 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000273B2AC65F0>
2024-12-03 23:30:00,103 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:30:00,103 DEBUG - send_request_headers.complete
2024-12-03 23:30:00,103 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:30:00,103 DEBUG - send_request_body.complete
2024-12-03 23:30:00,103 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:30:02,259 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:30:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'1501'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199942'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_0d7ca54bd024495f2c65268af867feb7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AsMU3hdy9rrjYp.2n7MiIt7sYt3c1DoNCdfXRE9rXc4-1733297401-1.0.1.1-e17gKNFX6onIUgWvFprocwCRieGsYsaFESdjBkg_WqYZUeF63cMkEfQEqG0bxR2iSQVO0RwXOjFEfxeXxkMS.g; path=/; expires=Wed, 04-Dec-24 08:00:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=YYF9H4awNTsqL477q_MNOZLS3pBPsjD0.YZJBPf0MA0-1733297401576-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca16aa98c32506-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:30:02,260 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:30:02,260 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:30:02,260 DEBUG - receive_response_body.complete
2024-12-03 23:30:02,260 DEBUG - response_closed.started
2024-12-03 23:30:02,260 DEBUG - response_closed.complete
2024-12-03 23:30:02,261 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Wed, 04 Dec 2024 07:30:01 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9rrum9u9hev9vwb50ku6dbbv'), ('openai-processing-ms', '1501'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199942'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '17ms'), ('x-request-id', 'req_0d7ca54bd024495f2c65268af867feb7'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=AsMU3hdy9rrjYp.2n7MiIt7sYt3c1DoNCdfXRE9rXc4-1733297401-1.0.1.1-e17gKNFX6onIUgWvFprocwCRieGsYsaFESdjBkg_WqYZUeF63cMkEfQEqG0bxR2iSQVO0RwXOjFEfxeXxkMS.g; path=/; expires=Wed, 04-Dec-24 08:00:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=YYF9H4awNTsqL477q_MNOZLS3pBPsjD0.YZJBPf0MA0-1733297401576-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8eca16aa98c32506-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-03 23:30:02,261 DEBUG - request_id: req_0d7ca54bd024495f2c65268af867feb7
2024-12-03 23:30:02,266 INFO - Assistant response: Hello! How can I assist you today with Kubernetes?
2024-12-03 23:30:14,868 INFO - 127.0.0.1 - - [03/Dec/2024 23:30:14] "POST /query HTTP/1.1" 200 -
2024-12-03 23:30:25,535 INFO - Starting the application...
2024-12-03 23:30:25,554 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:30:25,554 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:30:25,556 INFO -  * Restarting with stat
2024-12-03 23:30:27,728 INFO - Starting the application...
2024-12-03 23:30:27,738 WARNING -  * Debugger is active!
2024-12-03 23:30:27,744 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:30:29,429 DEBUG - Received query: hello
2024-12-03 23:30:29,436 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:30:29,468 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:30:29,468 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:30:29,539 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E044366B0>
2024-12-03 23:30:29,540 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017E043000C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:30:29,582 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E04436740>
2024-12-03 23:30:29,582 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:30:29,582 DEBUG - send_request_headers.complete
2024-12-03 23:30:29,582 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:30:29,582 DEBUG - send_request_body.complete
2024-12-03 23:30:29,582 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:30:30,195 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:30:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'524'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199942'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_0e7c9a1fa416ee25708ff56da212bd6a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fU.dVOjYIXYrs50ZeMmnLP.NhbazRf_QH58LUINywq8-1733297429-1.0.1.1-xT4_CQTSDj40okKyt5i7kaqgI6YGKoqdt0aNVwQYUkOzUr_5hINEeGYJVqPARUYO4XdcVWr4Fh66G.PiysPZhw; path=/; expires=Wed, 04-Dec-24 08:00:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=mmJFoBjNW1d9Yv409ehb6PhU2Q9r3OldSF45JE2aeAc-1733297429511-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1762d98867f6-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:30:30,196 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:30:30,196 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:30:30,196 DEBUG - receive_response_body.complete
2024-12-03 23:30:30,196 DEBUG - response_closed.started
2024-12-03 23:30:30,196 DEBUG - response_closed.complete
2024-12-03 23:30:30,197 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Wed, 04 Dec 2024 07:30:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9rrum9u9hev9vwb50ku6dbbv'), ('openai-processing-ms', '524'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199942'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '17ms'), ('x-request-id', 'req_0e7c9a1fa416ee25708ff56da212bd6a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=fU.dVOjYIXYrs50ZeMmnLP.NhbazRf_QH58LUINywq8-1733297429-1.0.1.1-xT4_CQTSDj40okKyt5i7kaqgI6YGKoqdt0aNVwQYUkOzUr_5hINEeGYJVqPARUYO4XdcVWr4Fh66G.PiysPZhw; path=/; expires=Wed, 04-Dec-24 08:00:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=mmJFoBjNW1d9Yv409ehb6PhU2Q9r3OldSF45JE2aeAc-1733297429511-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8eca1762d98867f6-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-03 23:30:30,197 DEBUG - request_id: req_0e7c9a1fa416ee25708ff56da212bd6a
2024-12-03 23:30:30,202 INFO - Assistant response: Hello! How can I assist you today with Kubernetes?
2024-12-03 23:30:30,203 INFO - 127.0.0.1 - - [03/Dec/2024 23:30:30] "POST /query HTTP/1.1" 200 -
2024-12-03 23:31:26,377 INFO -  * Detected change in 'C:\\Users\\Reason\\Desktop\\POST GRADUATION\\Job Search\\Cleric\\main.py', reloading
2024-12-03 23:31:26,574 INFO -  * Restarting with stat
2024-12-03 23:31:28,753 INFO - Starting the application...
2024-12-03 23:31:28,762 WARNING -  * Debugger is active!
2024-12-03 23:31:28,768 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:31:31,817 INFO -  * Detected change in 'C:\\Users\\Reason\\Desktop\\POST GRADUATION\\Job Search\\Cleric\\main.py', reloading
2024-12-03 23:31:32,003 INFO -  * Restarting with stat
2024-12-03 23:31:34,253 INFO - Starting the application...
2024-12-03 23:31:34,261 WARNING -  * Debugger is active!
2024-12-03 23:31:34,267 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:31:37,917 INFO - Starting the application...
2024-12-03 23:31:37,935 INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.1.84:8000
2024-12-03 23:31:37,935 INFO - [33mPress CTRL+C to quit[0m
2024-12-03 23:31:37,936 INFO -  * Restarting with stat
2024-12-03 23:31:40,323 INFO - Starting the application...
2024-12-03 23:31:40,332 WARNING -  * Debugger is active!
2024-12-03 23:31:40,338 INFO -  * Debugger PIN: 798-604-046
2024-12-03 23:31:44,313 DEBUG - Received query: hello
2024-12-03 23:31:44,321 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:31:44,349 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:31:44,350 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:31:44,426 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074A429E0>
2024-12-03 23:31:44,426 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002107490C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:31:44,466 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074A42A70>
2024-12-03 23:31:44,467 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:31:44,467 DEBUG - send_request_headers.complete
2024-12-03 23:31:44,467 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:31:44,467 DEBUG - send_request_body.complete
2024-12-03 23:31:44,467 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:31:44,983 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:31:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'410'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199942'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_ecda9560a6d092848bade03dfde7f175'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MWDFW5VhSiuKdpD2Lhk438OTAY7lOygbCW.35NRRnzk-1733297504-1.0.1.1-yHG1i2q.KgrRQsnLiLhgPnfEKSPssRXKP7q1L3m6fAyKGmStuiZgcrpUnvCbqap2iQuZ4i6jKovlRq7_prYRgw; path=/; expires=Wed, 04-Dec-24 08:01:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=93GdZUfOazi1oZoVJxlr3SoNWp.41rfyKNY9p0O5Owg-1733297504299-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1936dd762510-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:31:44,984 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:31:44,985 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:31:44,985 DEBUG - receive_response_body.complete
2024-12-03 23:31:44,985 DEBUG - response_closed.started
2024-12-03 23:31:44,985 DEBUG - response_closed.complete
2024-12-03 23:31:44,985 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Wed, 04 Dec 2024 07:31:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-9rrum9u9hev9vwb50ku6dbbv'), ('openai-processing-ms', '410'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199942'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '17ms'), ('x-request-id', 'req_ecda9560a6d092848bade03dfde7f175'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=MWDFW5VhSiuKdpD2Lhk438OTAY7lOygbCW.35NRRnzk-1733297504-1.0.1.1-yHG1i2q.KgrRQsnLiLhgPnfEKSPssRXKP7q1L3m6fAyKGmStuiZgcrpUnvCbqap2iQuZ4i6jKovlRq7_prYRgw; path=/; expires=Wed, 04-Dec-24 08:01:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=93GdZUfOazi1oZoVJxlr3SoNWp.41rfyKNY9p0O5Owg-1733297504299-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8eca1936dd762510-SJC'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-12-03 23:31:44,986 DEBUG - request_id: req_ecda9560a6d092848bade03dfde7f175
2024-12-03 23:31:44,991 INFO - Assistant response: Hello! How can I assist you with Kubernetes today?
2024-12-03 23:31:44,991 INFO - 127.0.0.1 - - [03/Dec/2024 23:31:44] "POST /query HTTP/1.1" 200 -
2024-12-03 23:32:33,443 DEBUG - Received query: Im just chillin how about you
2024-12-03 23:32:33,453 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:32:33,454 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:32:33,454 DEBUG - close.started
2024-12-03 23:32:33,454 DEBUG - close.complete
2024-12-03 23:32:33,455 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:32:33,515 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074A9EC50>
2024-12-03 23:32:33,515 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002107490C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:32:33,555 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074A9ED10>
2024-12-03 23:32:33,555 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:32:33,555 DEBUG - send_request_headers.complete
2024-12-03 23:32:33,555 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:32:33,555 DEBUG - send_request_body.complete
2024-12-03 23:32:33,555 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:32:50,134 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:32:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'16485'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199907'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'req_106252e6cdd8cc29528c76bb8e06b108'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1a69ad7fcf1a-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:32:50,135 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:32:50,135 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:32:50,135 DEBUG - receive_response_body.complete
2024-12-03 23:32:50,135 DEBUG - response_closed.started
2024-12-03 23:32:50,135 DEBUG - response_closed.complete
2024-12-03 23:32:50,136 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 04 Dec 2024 07:32:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '16485', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199907', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '27ms', 'x-request-id': 'req_106252e6cdd8cc29528c76bb8e06b108', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eca1a69ad7fcf1a-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-03 23:32:50,136 DEBUG - request_id: req_106252e6cdd8cc29528c76bb8e06b108
2024-12-03 23:32:50,136 INFO - Assistant response: I'm here to help with any Kubernetes questions you may have!
2024-12-03 23:32:50,137 INFO - 127.0.0.1 - - [03/Dec/2024 23:32:50] "POST /query HTTP/1.1" 200 -
2024-12-03 23:33:32,671 DEBUG - Received query: Tell  me about my kubernetes server
2024-12-03 23:33:32,682 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:33:32,682 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:33:32,683 DEBUG - close.started
2024-12-03 23:33:32,684 DEBUG - close.complete
2024-12-03 23:33:32,684 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:33:32,751 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074BA76A0>
2024-12-03 23:33:32,751 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002107490C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:33:32,792 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074BA7760>
2024-12-03 23:33:32,792 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:33:32,793 DEBUG - send_request_headers.complete
2024-12-03 23:33:32,793 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:33:32,793 DEBUG - send_request_body.complete
2024-12-03 23:33:32,793 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:33:33,447 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:33:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199865'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'40ms'), (b'x-request-id', b'req_c51a4bcb9c1a2df5a4d28ac26ec472cd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1bdbdc20fa22-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:33:33,448 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:33:33,448 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:33:33,448 DEBUG - receive_response_body.complete
2024-12-03 23:33:33,448 DEBUG - response_closed.started
2024-12-03 23:33:33,448 DEBUG - response_closed.complete
2024-12-03 23:33:33,449 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 04 Dec 2024 07:33:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '566', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199865', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '40ms', 'x-request-id': 'req_c51a4bcb9c1a2df5a4d28ac26ec472cd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eca1bdbdc20fa22-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-03 23:33:33,449 DEBUG - request_id: req_c51a4bcb9c1a2df5a4d28ac26ec472cd
2024-12-03 23:33:33,453 DEBUG - Starting new HTTP connection (1): 127.0.0.1:8000
2024-12-03 23:33:33,472 DEBUG - response body: {"kind":"NodeList","apiVersion":"v1","metadata":{"resourceVersion":"30457"},"items":[{"metadata":{"name":"minikube","uid":"1da6d62b-9b18-47da-9512-6a5783379000","resourceVersion":"30277","creationTimestamp":"2024-12-03T16:52:25Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube","kubernetes.io/os":"linux","minikube.k8s.io/commit":"210b148df93a80eb872ecbeb7e35281b3c582c61","minikube.k8s.io/name":"minikube","minikube.k8s.io/primary":"true","minikube.k8s.io/updated_at":"2024_12_03T08_52_29_0700","minikube.k8s.io/version":"v1.34.0","node-role.kubernetes.io/control-plane":"","node.kubernetes.io/exclude-from-external-load-balancers":""},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"unix:///var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}}},{"manager":"kubectl-label","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:30Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}}},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.0.0/24\"":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-12-04T07:29:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:nodeInfo":{"f:machineID":{},"f:systemUUID":{}}}},"subresource":"status"}]},"spec":{"podCIDR":"10.244.0.0/24","podCIDRs":["10.244.0.0/24"]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"1055762868Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"16344240Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"1055762868Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"16344240Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"True","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:25Z","reason":"KubeletReady","message":"kubelet is posting ready status"}],"addresses":[{"type":"InternalIP","address":"192.168.49.2"},{"type":"Hostname","address":"minikube"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"ed27252b2b58493fadae8f836533a702","systemUUID":"ed27252b2b58493fadae8f836533a702","bootID":"7221e3e8-6a3e-43d8-9184-6c3d92050c36","kernelVersion":"5.15.167.4-microsoft-standard-WSL2","osImage":"Ubuntu 22.04.4 LTS","containerRuntimeVersion":"docker://27.2.0","kubeletVersion":"v1.31.0","kubeProxyVersion":"","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["registry.k8s.io/etcd@sha256:a6dc63e6e8cfa0307d7851762fa6b629afb18f28d8aa3fab5a6e91b4af60026a","registry.k8s.io/etcd:3.5.15-0"],"sizeBytes":147945345},{"names":["registry.k8s.io/kube-apiserver@sha256:470179274deb9dc3a81df55cfc24823ce153147d4ebf2ed649a4f271f51eaddf","registry.k8s.io/kube-apiserver:v1.31.0"],"sizeBytes":94175876},{"names":["registry.k8s.io/kube-proxy@sha256:c727efb1c6f15a68060bf7f207f5c7a765355b7e3340c513e582ec819c5cd2fe","registry.k8s.io/kube-proxy:v1.31.0"],"sizeBytes":91471299},{"names":["registry.k8s.io/kube-controller-manager@sha256:f6f3c33dda209e8434b83dacf5244c03b59b0018d93325ff21296a142b68497d","registry.k8s.io/kube-controller-manager:v1.31.0"],"sizeBytes":88380387},{"names":["registry.k8s.io/kube-scheduler@sha256:96ddae9c9b2e79342e0551e2d2ec422c0c02629a74d928924aaa069706619808","registry.k8s.io/kube-scheduler:v1.31.0"],"sizeBytes":67363811},{"names":["registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1","registry.k8s.io/coredns/coredns:v1.11.1"],"sizeBytes":59820619},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a","registry.k8s.io/pause:3.10"],"sizeBytes":735760}]}}]}

2024-12-03 23:33:33,493 DEBUG - response body: {"kind":"ServiceList","apiVersion":"v1","metadata":{"resourceVersion":"30457"},"items":[{"metadata":{"name":"kubernetes","namespace":"default","uid":"a05e95ef-8a1b-4fa0-947f-93ae32dae6e5","resourceVersion":"199","creationTimestamp":"2024-12-03T16:52:27Z","labels":{"component":"apiserver","provider":"kubernetes"},"managedFields":[{"manager":"kube-apiserver","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{".":{},"f:component":{},"f:provider":{}}},"f:spec":{"f:clusterIP":{},"f:internalTrafficPolicy":{},"f:ipFamilyPolicy":{},"f:ports":{".":{},"k:{\"port\":443,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}}}]},"spec":{"ports":[{"name":"https","protocol":"TCP","port":443,"targetPort":8443}],"clusterIP":"10.96.0.1","clusterIPs":["10.96.0.1"],"type":"ClusterIP","sessionAffinity":"None","ipFamilies":["IPv4"],"ipFamilyPolicy":"SingleStack","internalTrafficPolicy":"Cluster"},"status":{"loadBalancer":{}}}]}

2024-12-03 23:33:33,513 DEBUG - response body: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30457"},"items":[]}

2024-12-03 23:33:33,533 DEBUG - response body: {"kind":"DeploymentList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30457"},"items":[]}

2024-12-03 23:33:33,534 INFO - 127.0.0.1 - - [03/Dec/2024 23:33:33] "GET /get_kube_api HTTP/1.1" 200 -
2024-12-03 23:33:33,557 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'function': {'arguments': '{"query":"Tell me about my kubernetes server","answer":"Fetching information about your Kubernetes cluster..."}', 'name': 'get_cluster_information'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'name': 'get_cluster_information', 'content': '{"query":"Tell  me about my kubernetes server","answer":"{\\"answer\\": \\"\\\\\\"{\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"minikube\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"status\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"role\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"unknown\\\\\\\\\\\\\\"}], \\\\\\\\\\\\\\"pods\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"deployments\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"services\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"kubernetes\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"type\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"ClusterIP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"cluster_ip\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"10.96.0.1\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"ports\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"https\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"protocol\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"TCP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"port\\\\\\\\\\\\\\": 443, \\\\\\\\\\\\\\"target_port\\\\\\\\\\\\\\": 8443, \\\\\\\\\\\\\\"node_port\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\"app_protocol\\\\\\\\\\\\\\": null}]}]}\\\\\\"\\", \\"query\\": \\"Get Kubernetes Cluster Info\\"}"}'}], 'model': 'gpt-4o-mini', 'tool_choice': None, 'tools': None}}
2024-12-03 23:33:33,558 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:33:33,559 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:33:33,560 DEBUG - send_request_headers.complete
2024-12-03 23:33:33,560 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:33:33,560 DEBUG - send_request_body.complete
2024-12-03 23:33:33,560 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:33:35,052 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:33:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'1414'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199665'), (b'x-ratelimit-reset-requests', b'16.518s'), (b'x-ratelimit-reset-tokens', b'100ms'), (b'x-request-id', b'req_78fa9917853b6713efc31e4da40ad049'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1be0aa2bfa22-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:33:35,053 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:33:35,053 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:33:35,053 DEBUG - receive_response_body.complete
2024-12-03 23:33:35,053 DEBUG - response_closed.started
2024-12-03 23:33:35,053 DEBUG - response_closed.complete
2024-12-03 23:33:35,054 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 04 Dec 2024 07:33:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '1414', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199665', 'x-ratelimit-reset-requests': '16.518s', 'x-ratelimit-reset-tokens': '100ms', 'x-request-id': 'req_78fa9917853b6713efc31e4da40ad049', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eca1be0aa2bfa22-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-03 23:33:35,054 DEBUG - request_id: req_78fa9917853b6713efc31e4da40ad049
2024-12-03 23:33:35,054 INFO - Assistant response: Your Kubernetes server has the following details:

- **Node**: 
  - Name: minikube
  - Status: Ready
  - Role: Unknown

- **Pods**: None

- **Deployments**: None

- **Services**:
  - Name: kubernetes
  - Type: ClusterIP
  - Cluster IP: 10.96.0.1
  - Ports: 
    - Name: https
    - Protocol: TCP
    - Port: 443
    - Target Port: 8443
2024-12-03 23:33:35,055 INFO - 127.0.0.1 - - [03/Dec/2024 23:33:35] "POST /query HTTP/1.1" 200 -
2024-12-03 23:33:41,483 DEBUG - Received query: Tell  me about my kubernetes server
2024-12-03 23:33:41,499 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'function': {'arguments': '{"query":"Tell me about my kubernetes server","answer":"Fetching information about your Kubernetes cluster..."}', 'name': 'get_cluster_information'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'name': 'get_cluster_information', 'content': '{"query":"Tell  me about my kubernetes server","answer":"{\\"answer\\": \\"\\\\\\"{\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"minikube\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"status\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"role\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"unknown\\\\\\\\\\\\\\"}], \\\\\\\\\\\\\\"pods\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"deployments\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"services\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"kubernetes\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"type\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"ClusterIP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"cluster_ip\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"10.96.0.1\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"ports\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"https\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"protocol\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"TCP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"port\\\\\\\\\\\\\\": 443, \\\\\\\\\\\\\\"target_port\\\\\\\\\\\\\\": 8443, \\\\\\\\\\\\\\"node_port\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\"app_protocol\\\\\\\\\\\\\\": null}]}]}\\\\\\"\\", \\"query\\": \\"Get Kubernetes Cluster Info\\"}"}'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:33:41,500 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:33:41,501 DEBUG - close.started
2024-12-03 23:33:41,501 DEBUG - close.complete
2024-12-03 23:33:41,501 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:33:41,576 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074C20580>
2024-12-03 23:33:41,576 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002107490C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:33:41,613 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074C20640>
2024-12-03 23:33:41,613 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:33:41,613 DEBUG - send_request_headers.complete
2024-12-03 23:33:41,613 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:33:41,614 DEBUG - send_request_body.complete
2024-12-03 23:33:41,614 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:33:42,280 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:33:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'579'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199486'), (b'x-ratelimit-reset-requests', b'17.097s'), (b'x-ratelimit-reset-tokens', b'154ms'), (b'x-request-id', b'req_aa677a563caeeed20d5b9732375fc46d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1c13084167ca-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:33:42,281 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:33:42,281 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:33:42,281 DEBUG - receive_response_body.complete
2024-12-03 23:33:42,281 DEBUG - response_closed.started
2024-12-03 23:33:42,281 DEBUG - response_closed.complete
2024-12-03 23:33:42,281 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 04 Dec 2024 07:33:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '579', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199486', 'x-ratelimit-reset-requests': '17.097s', 'x-ratelimit-reset-tokens': '154ms', 'x-request-id': 'req_aa677a563caeeed20d5b9732375fc46d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eca1c13084167ca-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-03 23:33:42,281 DEBUG - request_id: req_aa677a563caeeed20d5b9732375fc46d
2024-12-03 23:33:42,301 DEBUG - response body: {"kind":"NodeList","apiVersion":"v1","metadata":{"resourceVersion":"30462"},"items":[{"metadata":{"name":"minikube","uid":"1da6d62b-9b18-47da-9512-6a5783379000","resourceVersion":"30277","creationTimestamp":"2024-12-03T16:52:25Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube","kubernetes.io/os":"linux","minikube.k8s.io/commit":"210b148df93a80eb872ecbeb7e35281b3c582c61","minikube.k8s.io/name":"minikube","minikube.k8s.io/primary":"true","minikube.k8s.io/updated_at":"2024_12_03T08_52_29_0700","minikube.k8s.io/version":"v1.34.0","node-role.kubernetes.io/control-plane":"","node.kubernetes.io/exclude-from-external-load-balancers":""},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"unix:///var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}}},{"manager":"kubectl-label","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:30Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}}},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:33Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.0.0/24\"":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-12-04T07:29:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:nodeInfo":{"f:machineID":{},"f:systemUUID":{}}}},"subresource":"status"}]},"spec":{"podCIDR":"10.244.0.0/24","podCIDRs":["10.244.0.0/24"]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"1055762868Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"16344240Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"1055762868Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"16344240Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:24Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"True","lastHeartbeatTime":"2024-12-04T07:29:49Z","lastTransitionTime":"2024-12-03T16:52:25Z","reason":"KubeletReady","message":"kubelet is posting ready status"}],"addresses":[{"type":"InternalIP","address":"192.168.49.2"},{"type":"Hostname","address":"minikube"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"ed27252b2b58493fadae8f836533a702","systemUUID":"ed27252b2b58493fadae8f836533a702","bootID":"7221e3e8-6a3e-43d8-9184-6c3d92050c36","kernelVersion":"5.15.167.4-microsoft-standard-WSL2","osImage":"Ubuntu 22.04.4 LTS","containerRuntimeVersion":"docker://27.2.0","kubeletVersion":"v1.31.0","kubeProxyVersion":"","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["registry.k8s.io/etcd@sha256:a6dc63e6e8cfa0307d7851762fa6b629afb18f28d8aa3fab5a6e91b4af60026a","registry.k8s.io/etcd:3.5.15-0"],"sizeBytes":147945345},{"names":["registry.k8s.io/kube-apiserver@sha256:470179274deb9dc3a81df55cfc24823ce153147d4ebf2ed649a4f271f51eaddf","registry.k8s.io/kube-apiserver:v1.31.0"],"sizeBytes":94175876},{"names":["registry.k8s.io/kube-proxy@sha256:c727efb1c6f15a68060bf7f207f5c7a765355b7e3340c513e582ec819c5cd2fe","registry.k8s.io/kube-proxy:v1.31.0"],"sizeBytes":91471299},{"names":["registry.k8s.io/kube-controller-manager@sha256:f6f3c33dda209e8434b83dacf5244c03b59b0018d93325ff21296a142b68497d","registry.k8s.io/kube-controller-manager:v1.31.0"],"sizeBytes":88380387},{"names":["registry.k8s.io/kube-scheduler@sha256:96ddae9c9b2e79342e0551e2d2ec422c0c02629a74d928924aaa069706619808","registry.k8s.io/kube-scheduler:v1.31.0"],"sizeBytes":67363811},{"names":["registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1","registry.k8s.io/coredns/coredns:v1.11.1"],"sizeBytes":59820619},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a","registry.k8s.io/pause:3.10"],"sizeBytes":735760}]}}]}

2024-12-03 23:33:42,322 DEBUG - response body: {"kind":"ServiceList","apiVersion":"v1","metadata":{"resourceVersion":"30463"},"items":[{"metadata":{"name":"kubernetes","namespace":"default","uid":"a05e95ef-8a1b-4fa0-947f-93ae32dae6e5","resourceVersion":"199","creationTimestamp":"2024-12-03T16:52:27Z","labels":{"component":"apiserver","provider":"kubernetes"},"managedFields":[{"manager":"kube-apiserver","operation":"Update","apiVersion":"v1","time":"2024-12-03T16:52:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{".":{},"f:component":{},"f:provider":{}}},"f:spec":{"f:clusterIP":{},"f:internalTrafficPolicy":{},"f:ipFamilyPolicy":{},"f:ports":{".":{},"k:{\"port\":443,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}}}]},"spec":{"ports":[{"name":"https","protocol":"TCP","port":443,"targetPort":8443}],"clusterIP":"10.96.0.1","clusterIPs":["10.96.0.1"],"type":"ClusterIP","sessionAffinity":"None","ipFamilies":["IPv4"],"ipFamilyPolicy":"SingleStack","internalTrafficPolicy":"Cluster"},"status":{"loadBalancer":{}}}]}

2024-12-03 23:33:42,340 DEBUG - response body: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30463"},"items":[]}

2024-12-03 23:33:42,356 DEBUG - response body: {"kind":"DeploymentList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30463"},"items":[]}

2024-12-03 23:33:42,357 INFO - 127.0.0.1 - - [03/Dec/2024 23:33:42] "GET /get_kube_api HTTP/1.1" 200 -
2024-12-03 23:33:42,377 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'function': {'arguments': '{"query":"Tell me about my kubernetes server","answer":"Fetching information about your Kubernetes cluster..."}', 'name': 'get_cluster_information'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'name': 'get_cluster_information', 'content': '{"query":"Tell  me about my kubernetes server","answer":"{\\"answer\\": \\"\\\\\\"{\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"minikube\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"status\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"role\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"unknown\\\\\\\\\\\\\\"}], \\\\\\\\\\\\\\"pods\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"deployments\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"services\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"kubernetes\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"type\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"ClusterIP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"cluster_ip\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"10.96.0.1\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"ports\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"https\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"protocol\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"TCP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"port\\\\\\\\\\\\\\": 443, \\\\\\\\\\\\\\"target_port\\\\\\\\\\\\\\": 8443, \\\\\\\\\\\\\\"node_port\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\"app_protocol\\\\\\\\\\\\\\": null}]}]}\\\\\\"\\", \\"query\\": \\"Get Kubernetes Cluster Info\\"}"}'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_e1O9BCcUFMV5B5qOUKM1dfPz', 'function': {'arguments': '{"query":"Tell me about my kubernetes server","answer":"Fetching information about your Kubernetes cluster..."}', 'name': 'get_cluster_information'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_e1O9BCcUFMV5B5qOUKM1dfPz', 'name': 'get_cluster_information', 'content': '{"query":"Tell  me about my kubernetes server","answer":"{\\"answer\\": \\"\\\\\\"{\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"minikube\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"status\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"role\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"unknown\\\\\\\\\\\\\\"}], \\\\\\\\\\\\\\"pods\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"deployments\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"services\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"kubernetes\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"type\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"ClusterIP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"cluster_ip\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"10.96.0.1\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"ports\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"https\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"protocol\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"TCP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"port\\\\\\\\\\\\\\": 443, \\\\\\\\\\\\\\"target_port\\\\\\\\\\\\\\": 8443, \\\\\\\\\\\\\\"node_port\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\"app_protocol\\\\\\\\\\\\\\": null}]}]}\\\\\\"\\", \\"query\\": \\"Get Kubernetes Cluster Info\\"}"}'}], 'model': 'gpt-4o-mini', 'tool_choice': None, 'tools': None}}
2024-12-03 23:33:42,379 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:33:42,379 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:33:42,380 DEBUG - send_request_headers.complete
2024-12-03 23:33:42,380 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:33:42,380 DEBUG - send_request_body.complete
2024-12-03 23:33:42,380 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:33:43,961 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:33:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'1498'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199286'), (b'x-ratelimit-reset-requests', b'24.973s'), (b'x-ratelimit-reset-tokens', b'214ms'), (b'x-request-id', b'req_2e9046e3ada684a30dc3e3c38ce1ae93'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1c17cd1267ca-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:33:43,961 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:33:43,962 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:33:43,962 DEBUG - receive_response_body.complete
2024-12-03 23:33:43,962 DEBUG - response_closed.started
2024-12-03 23:33:43,962 DEBUG - response_closed.complete
2024-12-03 23:33:43,962 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 04 Dec 2024 07:33:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '1498', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199286', 'x-ratelimit-reset-requests': '24.973s', 'x-ratelimit-reset-tokens': '214ms', 'x-request-id': 'req_2e9046e3ada684a30dc3e3c38ce1ae93', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eca1c17cd1267ca-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-03 23:33:43,962 DEBUG - request_id: req_2e9046e3ada684a30dc3e3c38ce1ae93
2024-12-03 23:33:43,963 INFO - Assistant response: Your Kubernetes server has the following details:

- **Node**: 
  - Name: minikube
  - Status: Ready
  - Role: Unknown

- **Pods**: None

- **Deployments**: None

- **Services**:
  - Name: kubernetes
  - Type: ClusterIP
  - Cluster IP: 10.96.0.1
  - Ports: 
    - Name: https
    - Protocol: TCP
    - Port: 443
    - Target Port: 8443
2024-12-03 23:33:43,963 INFO - 127.0.0.1 - - [03/Dec/2024 23:33:43] "POST /query HTTP/1.1" 200 -
2024-12-03 23:34:02,437 DEBUG - Received query: How many nodes are their?
2024-12-03 23:34:02,460 DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Kubernetes assistant that responds to queries with concise, brief answers.Do not include extra details, only provide the essential information.'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'assistant', 'content': 'Hello! How can I assist you with Kubernetes today?'}, {'role': 'user', 'content': 'Im just chillin how about you'}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'assistant', 'content': "I'm here to help with any Kubernetes questions you may have!"}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'function': {'arguments': '{"query":"Tell me about my kubernetes server","answer":"Fetching information about your Kubernetes cluster..."}', 'name': 'get_cluster_information'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_INKtx2qPOtCtOJ5YJXOMpjqk', 'name': 'get_cluster_information', 'content': '{"query":"Tell  me about my kubernetes server","answer":"{\\"answer\\": \\"\\\\\\"{\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"minikube\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"status\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"role\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"unknown\\\\\\\\\\\\\\"}], \\\\\\\\\\\\\\"pods\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"deployments\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"services\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"kubernetes\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"type\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"ClusterIP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"cluster_ip\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"10.96.0.1\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"ports\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"https\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"protocol\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"TCP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"port\\\\\\\\\\\\\\": 443, \\\\\\\\\\\\\\"target_port\\\\\\\\\\\\\\": 8443, \\\\\\\\\\\\\\"node_port\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\"app_protocol\\\\\\\\\\\\\\": null}]}]}\\\\\\"\\", \\"query\\": \\"Get Kubernetes Cluster Info\\"}"}'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'user', 'content': 'Tell  me about my kubernetes server'}, {'content': None, 'refusal': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_e1O9BCcUFMV5B5qOUKM1dfPz', 'function': {'arguments': '{"query":"Tell me about my kubernetes server","answer":"Fetching information about your Kubernetes cluster..."}', 'name': 'get_cluster_information'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_e1O9BCcUFMV5B5qOUKM1dfPz', 'name': 'get_cluster_information', 'content': '{"query":"Tell  me about my kubernetes server","answer":"{\\"answer\\": \\"\\\\\\"{\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"minikube\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"status\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"role\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"unknown\\\\\\\\\\\\\\"}], \\\\\\\\\\\\\\"pods\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"deployments\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\"services\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"kubernetes\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"type\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"ClusterIP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"cluster_ip\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"10.96.0.1\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"ports\\\\\\\\\\\\\\": [{\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"https\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"protocol\\\\\\\\\\\\\\": \\\\\\\\\\\\\\"TCP\\\\\\\\\\\\\\", \\\\\\\\\\\\\\"port\\\\\\\\\\\\\\": 443, \\\\\\\\\\\\\\"target_port\\\\\\\\\\\\\\": 8443, \\\\\\\\\\\\\\"node_port\\\\\\\\\\\\\\": null, \\\\\\\\\\\\\\"app_protocol\\\\\\\\\\\\\\": null}]}]}\\\\\\"\\", \\"query\\": \\"Get Kubernetes Cluster Info\\"}"}'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'assistant', 'content': 'Your Kubernetes server has the following details:\n\n- **Node**: \n  - Name: minikube\n  - Status: Ready\n  - Role: Unknown\n\n- **Pods**: None\n\n- **Deployments**: None\n\n- **Services**:\n  - Name: kubernetes\n  - Type: ClusterIP\n  - Cluster IP: 10.96.0.1\n  - Ports: \n    - Name: https\n    - Protocol: TCP\n    - Port: 443\n    - Target Port: 8443'}, {'role': 'user', 'content': 'How many nodes are their?'}], 'model': 'gpt-4o-mini', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_cluster_information', 'description': 'Use this function to get information about the Kubernetes cluster', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'This is the query from the user'}, 'answer': {'type': 'string', 'description': "The assistant's answer to the query"}}, 'required': ['query', 'answer']}}}]}}
2024-12-03 23:34:02,462 DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-12-03 23:34:02,462 DEBUG - close.started
2024-12-03 23:34:02,462 DEBUG - close.complete
2024-12-03 23:34:02,462 DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-12-03 23:34:02,528 DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074C31030>
2024-12-03 23:34:02,529 DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002107490C0C0> server_hostname='api.openai.com' timeout=5.0
2024-12-03 23:34:02,567 DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021074BA7670>
2024-12-03 23:34:02,567 DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-12-03 23:34:02,568 DEBUG - send_request_headers.complete
2024-12-03 23:34:02,568 DEBUG - send_request_body.started request=<Request [b'POST']>
2024-12-03 23:34:02,568 DEBUG - send_request_body.complete
2024-12-03 23:34:02,568 DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-12-03 23:34:03,052 DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 04 Dec 2024 07:34:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-9rrum9u9hev9vwb50ku6dbbv'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199110'), (b'x-ratelimit-reset-requests', b'13.424s'), (b'x-ratelimit-reset-tokens', b'267ms'), (b'x-request-id', b'req_b15d2bb202b751a3b57b8c0db5805890'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8eca1c95fe9ceb2c-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-12-03 23:34:03,053 INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-12-03 23:34:03,053 DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-12-03 23:34:03,053 DEBUG - receive_response_body.complete
2024-12-03 23:34:03,053 DEBUG - response_closed.started
2024-12-03 23:34:03,053 DEBUG - response_closed.complete
2024-12-03 23:34:03,053 DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Wed, 04 Dec 2024 07:34:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-9rrum9u9hev9vwb50ku6dbbv', 'openai-processing-ms': '401', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199110', 'x-ratelimit-reset-requests': '13.424s', 'x-ratelimit-reset-tokens': '267ms', 'x-request-id': 'req_b15d2bb202b751a3b57b8c0db5805890', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8eca1c95fe9ceb2c-SJC', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-12-03 23:34:03,054 DEBUG - request_id: req_b15d2bb202b751a3b57b8c0db5805890
2024-12-03 23:34:03,054 INFO - Assistant response: There is 1 node in your Kubernetes server.
2024-12-03 23:34:03,054 INFO - 127.0.0.1 - - [03/Dec/2024 23:34:03] "POST /query HTTP/1.1" 200 -
2024-12-03 23:34:39,231 INFO -  * Detected change in 'C:\\Users\\Reason\\Desktop\\POST GRADUATION\\Job Search\\Cleric\\main.py', reloading
2024-12-03 23:34:39,403 INFO -  * Restarting with stat
